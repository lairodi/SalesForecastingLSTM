# Introduction
In today’s highly competitive retail business environment, it is essential to maintain a balance between meeting consumer demands and the cost of inventory. Carrying a bigger inventory enables customer demand to be met, but at the cost of over-stocking of parts and products, causing capital to be tied up and also may result in lower profits. On the other hand, even though lower inventory may decrease inventory expenses, it may result in missed selling opportunities, customer dissatisfaction and other issues. Knowing how much to make and sell, as well as when to sell is key to helping a company increase profits and reduce costs. This information is especially important in manufacturing scheduling to help keep factory costs low by knowing when to increase or decrease temporary labor and other factory expenses in order to control factory costs.

Demand forecasting aids strategic production planning in an industry as it allows managers to anticipate the future and plan joint activities with the functional areas (Veiga, Veiga, Puchalski, Coelho, & Tortato, 2016) [1].Sales forecasting plays an extremely critical role in predicting future sales by examining historical sales for the same time period. It can be as simple as using an excel sheet to track sales and then applying a simple formula to determine future sales or can be as complex as applying machine learning (deep learning) to build ML models based on sales data and then predicting future sales using these models. 


# Problem definition
In this project, we will be analyzing the sales data for a window covering manufacturing company and  applying deep learning to predict (or forecast) the sales for a particular product category using the Long Short-term Memory (LSTM)[2] method (a popular recurrent neural network that can learn the order dependence between items in a sequence). We will use Keras v2.0 [3] with the TensorFlow backend to implement LSTM. A benefit of LSTMs in addition to learning long sequences is that they can learn to make a one-shot multi-step forecast which may be useful for time series forecasting.  

# Long Short-Term Memory Networks
Recurrent neural networks are networks with loops in them, allowing information to persist. They can be thought of as multiple copies of the same network, each passing a message to a successor. One of the appeals of RNNs is that they are be able to connect previous information to the present task. For e.g. looking at previous words in a sentence and predicting the next word. In cases where the gap between the relevant information and the place that it’s needed is small, RNNs can learn to use the past information. As the gap between current and previous information grows, RNNs are unable to learn to connect the information and will not be as effective. 

 Long Short Term Memory networks (LSTM) are a special kind of RNN, capable of learning long-term dependencies in sequence prediction problems [4]. A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell [5].
